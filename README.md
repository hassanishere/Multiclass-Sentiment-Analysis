This project finetunes various pretrained models namely, BERT, RoBERTa, DistilBERT and GPT-2 on a downstream task of sentiment detection. The data used has been collected from Amazon book reviews and contains various features.
The features of interest for this project are the Review Text and the Rating Label. 

Review Text: Contains the review written by the customer. 
Rating Label: Multiclass label ranging from 1-5

We have employed varuiious models, compared them through robust measures such as Recall, Precision and F-1 as well as thoroughly analysed misclassified reviews to better understand the underlying behaviour behind these models. 

